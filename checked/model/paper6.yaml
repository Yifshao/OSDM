简称: ProphetNet
任务: 文本摘要
论文:
  题目: 'ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training'
  作者:
  - Weizhen Qi
  - Yu Yan
  - Yeyun Gong
  - Dayiheng Liu
  - Nan Duan
  - Jiusheng Chen
  - Ruofei Zhang
  - Ming Zhou
  单位:
  - University of Science and Technology of China
  - Microsoft
  - Microsoft Research Asia
  - Sichuan University
  发表年份: 2020
  卷（号）: EMNLP-2020
  出版社: Association for Computational Linguistics
  页码: 2401--2410
  下载地址: https://www.aclweb.org/anthology/2020.findings-emnlp.217.pdf
  引用次数: 34
代码:
  地址: https://github.com/neulab/guided_summarization
  时间: 2020
  star数量: 229
  fork数量: 44
  编程语言: Python
  框架: torch==1.3.0 fairseq==v0.9.0
模型性能:
  数据集:
    CNN / Daily Mail:
      ROUGE-1: 44.2
      ROUGE-2: 21.17
      ROUGE-L: 41.3
    Gigaword:
      ROUGE-1: 39.51
      ROUGE-2: 20.42
      ROUGE-L: 36.69
    SQuAD v1.1:
      B4: 25.8
      MTR: 27.54
      ROUGE-L: 53.65
关键技术: Large-scale pretrained Seq2Seq model
简介: 本文提出了一种新的大规模预训练Seq2Seq模型Prephetnet。相较传统语言模型的一步预测，Prephet实现了自监督的多步预测。
简介链接: None
