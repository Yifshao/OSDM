简称: Joint Entity and Relation Extraction
任务: 'Relation Extraction'
论文: 
  题目: 'Two are Better than One: Joint Entity and Relation Extraction with Table-Sequence Encoders'
  作者:
    - Jue Wang
    - Wei Lu
  单位:
    - College of Computer Science and Technology, Zhejiang University
    - StatNLP Research Group, Singapore University of Technology and Design
  发表年份: 2020
  卷（号）: None
  出版社: Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)
  页码: 1706--1721
  下载地址: https://www.aclweb.org/anthology/2020.emnlp-main.133.pdf
  引用次数: None
代码:
  地址: 'https://github.com/LorrinWWW/two-are-better-than-one'
  时间: 2020
  star数量: 61
  fork数量: 16
  编程语言: python3
  框架: pytorch 1.4.0
模型性能: 
  数据集:
    - ACE04:
      - NER: 88.6
      - RE: 63.3
      - RE+: 59.6
    - ACE05:
      - NER: 89.5
      - RE: 67.6
      - RE+: 64.3
    - CoNLL04(micro-averaged F1):
      - NER: 90.1
      - RE: 73.8
      - RE+: 73.6
    - CoNLL04(macro-averaged F1):
      - NER: 86.9
      - RE: 75.8
      - RE+: 75.4
    - ADE:
      - NER: 89.7
      - RE: 80.1
      - RE+: 80.1
关键技术: '序列表编码器'
简介: '在本文中，我们提出了一种新的方法来解决局限性。我们不是用单一的表示来预测实体和关系，而是专注于学习两种表示，分别用于NER和RE的序列表示和表表示。一方面，这两种不同的表示可以用于捕获特定于任务的信息。另一方面，我们设计了一种机制来允许它们彼此交互，以便利用NER和RE任务背后的内在关联。此外，我们采用神经网络架构，可以更好地捕捉二维表表示中的结构信息。我们将看到，这种结构信息(特别是表中相邻条目的上下文)对于获得更好的性能是至关重要的。'
简介链接: 'https://www.cnblogs.com/riddle/p/13925088.html'

  




